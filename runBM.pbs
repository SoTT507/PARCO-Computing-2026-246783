#!/bin/bash
#PBS -N bench_SpMV

#PBS -o ./bench_out.info
#PBS -e ./err.info
#PBS -q shortCPUQ

#PBS -l walltime=00:10:00

#PBS -l select=2:ncpus=64:mem=50gb

cd "$PBS_O_WORKDIR"

module load GCCcore/12.2.0
module load zlib/1.2.12-GCCcore-12.2.0
module load binutils/2.39-GCCcore-12.2.0
module load GCC/12.2.0
module load ncurses/6.3-GCCcore-12.2.0
module load bzip2/1.0.8-GCCcore-12.2.0
module load OpenSSL/1.1
module load cURL/7.86.0-GCCcore-12.2.0
module load XZ/5.2.7-GCCcore-12.2.0
module load libarchive/3.6.1-GCCcore-12.2.0
module load CMake/3.24.3-GCCcore-12.2.0
module load numactl/2.0.16-GCCcore-12.2.0
module load libxml2/2.10.3-GCCcore-12.2.0
module load libpciaccess/0.17-GCCcore-12.2.0
module load hwloc/2.8.0-GCCcore-12.2.0
module load libevent/2.1.12-GCCcore-12.2.0
module load UCX/1.13.1-GCCcore-12.2.0
module load libfabric/1.16.1-GCCcore-12.2.0
module load PMIx/4.2.2-GCCcore-12.2.0
module load UCC/1.1.0-GCCcore-12.2.0
module load OpenMPI/4.1.4-GCC-12.2.0

TOTAL_CORES=128
NODES=2

MPI_PER_NODE_LIST="1 2 4 8 16 32 64 128"

for MPI_PER_NODE in $MPI_PER_NODE_LIST
do
    MPI_PROCS=$((MPI_PER_NODE * NODES))
    OMP_THREADS=$((TOTAL_CORES / MPI_PROCS))

    export OMP_NUM_THREADS=$OMP_THREADS
    export OMP_PROC_BIND=close
    export OMP_PLACES=cores

    echo "MPI=$MPI_PROCS  OMP=$OMP_THREADS"

    mpiexec -n $MPI_PROCS --oversubscribe ./d2_SpMV

    RESULT_NAME="plots/result_MPI${MPI_PROCS}_OMP${OMP_THREADS}.csv"
    cp mpi_spmv_results.csv "$RESULT_NAME"
    rm mpi_spmv_results.csv
done
